services:
  kafka:
    image: apache/kafka:3.7.0
    container_name: kafka
    ports:
      # External listener for tools running on your host (Windows)
      - "9092:9092"
    environment:
      # KRaft single-node
      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: "broker,controller"
      KAFKA_CONTROLLER_QUORUM_VOTERS: "1@kafka:9093"
      KAFKA_CONTROLLER_LISTENER_NAMES: "CONTROLLER"

      # Listeners: internal for containers, external for host, controller for kraft
      KAFKA_LISTENERS: "INTERNAL://:29092,EXTERNAL://:9092,CONTROLLER://:9093"
      KAFKA_ADVERTISED_LISTENERS: "INTERNAL://kafka:29092,EXTERNAL://localhost:9092"
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: "INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT,CONTROLLER:PLAINTEXT"
      KAFKA_INTER_BROKER_LISTENER_NAME: "INTERNAL"

      # Dev-friendly defaults
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "false"
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0

    volumes:
      - kafka_data:/var/lib/kafka/data
    networks:
      - realtime_net
  
  schema-registry:
    image: confluentinc/cp-schema-registry:7.5.0
    container_name: schema-registry
    ports:
      - "8081:8081"
    environment:
      SCHEMA_REGISTRY_HOST_NAME: schema-registry
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: PLAINTEXT://kafka:29092
      SCHEMA_REGISTRY_LISTENERS: http://0.0.0.0:8081
    depends_on:
      - kafka
    networks:
      - realtime_net

  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: kafka-ui
    ports:
      - "8080:8080"
    environment:
      - KAFKA_CLUSTERS_0_NAME=local
      - KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS=kafka:29092
      - KAFKA_CLUSTERS_0_SCHEMAREGISTRY=http://schema-registry:8081
    depends_on:
      - kafka
      - schema-registry
    networks:
      - realtime_net

  kafka-init:
    image: apache/kafka:3.7.0
    container_name: kafka-init
    depends_on:
      - kafka
    entrypoint: /bin/bash
    command: -c "
        set -e;

        echo 'Waiting for Kafka...';

        for i in {1..30}; do
          /opt/kafka/bin/kafka-topics.sh --bootstrap-server kafka:29092 --list >/dev/null 2>&1 && break;
          echo \"Kafka not ready yet ($i/30)...\";
          sleep 2;
        done;

        echo 'Creating topics...';

        /opt/kafka/bin/kafka-topics.sh --bootstrap-server kafka:29092 \
          --create --if-not-exists \
          --topic sales.events.v1 \
          --partitions 3 \
          --replication-factor 1;

        /opt/kafka/bin/kafka-topics.sh --bootstrap-server kafka:29092 \
          --create --if-not-exists \
          --topic sales.events.dlq.v1 \
          --partitions 3 \
          --replication-factor 1;

        echo 'Topics created:';
        /opt/kafka/bin/kafka-topics.sh --bootstrap-server kafka:29092 --list;
      "

    networks:
      - realtime_net
    restart: "no"

  producer:
    build:
      context: ./producer
    container_name: producer
    environment:
      KAFKA_BOOTSTRAP_SERVERS: kafka:29092
      SCHEMA_REGISTRY_URL: http://schema-registry:8081
      KAFKA_TOPIC: sales.events.v1
      KAFKA_DLQ_TOPIC: sales.events.dlq.v1
      EVENTS_PER_SEC: "5"
      DUPLICATE_RATE: "0.02"
      LATE_EVENT_RATE: "0.05"
      MAX_LATE_SECONDS: "600"
    depends_on:
      - kafka
      - schema-registry
      - kafka-init
    networks:
      - realtime_net
    restart: unless-stopped

  spark-master:
    build:
      context: ./streaming
    container_name: spark-master
    command: bash -lc "/opt/spark/sbin/start-master.sh && tail -f /opt/spark/logs/*"
    ports:
      - "8088:8080"   # Spark Master UI (avoid clashing with Kafka UI)
      - "7077:7077"   # Spark master port
    networks:
      - realtime_net

  spark-worker-1:
    build:
      context: ./streaming
    container_name: spark-worker-1
    depends_on:
      - spark-master
    command: bash -lc "/opt/spark/sbin/start-worker.sh spark://spark-master:7077 && tail -f /opt/spark/logs/*"
    environment:
      SPARK_WORKER_CORES: "2"
      SPARK_WORKER_MEMORY: "2g"
    networks:
      - realtime_net

  spark-job:
    build:
      context: ./streaming
    container_name: spark-job
    depends_on:
      - kafka
      - schema-registry
      - spark-master
      - spark-worker-1
      - producer
    environment:
      KAFKA_BOOTSTRAP_SERVERS: kafka:29092
      SCHEMA_REGISTRY_URL: http://schema-registry:8081
      KAFKA_TOPIC: sales.events.v1
      CHECKPOINT_DIR: /data/checkpoints/revenue_5m
      GOLD_DIR: /data/gold/revenue_5m
      WATERMARK_DELAY: "10 minutes"
      TRIGGER_INTERVAL: "10 seconds"
    volumes:
      - ./data:/data
    command: >
      bash -lc "sleep 15 && /opt/spark/bin/spark-submit --master spark://spark-master:7077 --deploy-mode client --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.3 /app/src/stream_sales_agg.py"
    networks:
      - realtime_net
    restart: unless-stopped

volumes:
  kafka_data:

networks:
  realtime_net:
    driver: bridge